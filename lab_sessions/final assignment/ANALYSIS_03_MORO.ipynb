{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORO\n",
    "\n",
    "This notebook runs MORO. This file has been run on an enterprise system with 80 cpu cores in order to speed up the simulation times.\n",
    "The PRIM scenario's are imported but as the range of these scenario's spans the complete uncertainty space a sample of 100 scenarios is used for the robust_optimizations. \n",
    "\n",
    "In order to run robustness metrics, the found MORO solutions are re-evaluated toghether with some random policies.\n",
    "\n",
    "Input:  ANALYSIS_results/02_PRIM_scenarios.txt\n",
    "Output: ANALYSIS_results/03_MORO_results.csv\n",
    "        ANALYSIS_results/03_MORO_convergence.csv\n",
    "        ANALYSIS_results/03_robust_results.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from ema_workbench.analysis import plotting, plotting_util, pairs_plotting, prim\n",
    "from ema_workbench import (RealParameter, ScalarOutcome, Constant,\n",
    "                           Model, MultiprocessingEvaluator, SequentialEvaluator, ema_logging,\n",
    "                           perform_experiments, Policy, Scenario)\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume,\n",
    "                                                     EpsilonProgress)\n",
    "from ema_workbench import Constraint\n",
    "from ema_workbench.util.utilities import (save_results, load_results)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define problem formulation\n",
    "model, functions = get_model_for_problem_formulation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up robust functions\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def robustness(direction, threshold, data):\n",
    "    if direction == 'SMALLER':\n",
    "        return np.sum(data<=threshold)/data.shape[0]\n",
    "    else:\n",
    "        return np.sum(data>=threshold)/data.shape[0]\n",
    "\n",
    "def costs(data):\n",
    "    return data[0] / 1e9\n",
    "\n",
    "Expected_Annual_Damage = functools.partial(robustness, 'SMALLER', 1*10**6)\n",
    "Dike_Investment_Costs = functools.partial(robustness, 'SMALLER', 10*10**8)\t\n",
    "RfR_Investment_Costs = functools.partial(robustness, 'SMALLER', 1)\t\n",
    "Evacuation_Costs = functools.partial(robustness, 'SMALLER', 50000)\t\n",
    "Expected_Number_of_Deaths = functools.partial(robustness, 'SMALLER', 0.5)\n",
    "Minimum_water_level_full_network = functools.partial(robustness, 'LARGER', 4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the robustness functions\n",
    "robust = [ScalarOutcome('FExpected_Damage', kind=ScalarOutcome.MAXIMIZE, variable_name='Expected Annual Damage',\n",
    "                        function=Expected_Annual_Damage),\n",
    "          ScalarOutcome('FEvacuation_Costs', kind=ScalarOutcome.MINIMIZE, variable_name='Evacuation Costs', \n",
    "                        function=costs),\n",
    "          ScalarOutcome('FNumber_of_Deaths', kind=ScalarOutcome.MAXIMIZE, variable_name='Expected Number of Deaths',\n",
    "                        function=Expected_Number_of_Deaths),\n",
    "          ScalarOutcome('Fwl', kind=ScalarOutcome.MAXIMIZE, variable_name='Minimum water level full network',\n",
    "                        function=Minimum_water_level_full_network)   \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up convergence metrics\n",
    "convergence_metrics = [HyperVolume(minimum=[0,0,0,0], maximum=[1.1, 3, 1.1, 1.1]), EpsilonProgress()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check epsilon and convergence\n",
    "def plot_epsilon_and_convergence(convergencedata):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "    ax1.plot(convergencedata.nfe, convergencedata.epsilon_progress)\n",
    "    ax1.set_ylabel('$\\epsilon$-progress')\n",
    "    ax2.plot(convergencedata.nfe, convergencedata.hypervolume)\n",
    "    ax2.set_ylabel('hypervolume')\n",
    "\n",
    "    ax1.set_xlabel('number of function evaluations')\n",
    "    ax2.set_xlabel('number of function evaluations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scenarios from PRIM analysis ## depreciated\n",
    "import pickle\n",
    "\n",
    "with open('ANALYSIS_results/02_PRIM_scenarios.txt', 'rb') as file:\n",
    "    scenarios = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform MORO\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    robust_results, convergence = evaluator.robust_optimize(robust, \n",
    "                                                    scenarios=100,\n",
    "                                                    nfe = 10000,\n",
    "                                                    epsilons=[0.05, ] * len(robust),\n",
    "                                                    convergence=convergence_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect convergence\n",
    "plot_epsilon_and_convergence(convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust policies\n",
    "robust_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "robust_result.to_csv('ANALYSIS_results/03_MORO_results.csv')\n",
    "convergence.to_csv('ANALYSIS_results/03_MORO_convergence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 random policies\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    r1, r2 = evaluator.perform_experiments(1,\n",
    "                                         policies = 10)\n",
    "    \n",
    "policies = robust_results[['0_RfR 0', '0_RfR 1', '0_RfR 2', '1_RfR 0', '1_RfR 1', '1_RfR 2', '2_RfR 0', '2_RfR 1', '2_RfR 2', '3_RfR 0', '3_RfR 1', '3_RfR 2', '4_RfR 0', '4_RfR 1', '4_RfR 2', 'EWS_DaysToThreat', 'A.1_DikeIncrease 0', 'A.1_DikeIncrease 1', 'A.1_DikeIncrease 2', 'A.2_DikeIncrease 0', 'A.2_DikeIncrease 1', 'A.2_DikeIncrease 2', 'A.3_DikeIncrease 0', 'A.3_DikeIncrease 1', 'A.3_DikeIncrease 2', 'A.4_DikeIncrease 0', 'A.4_DikeIncrease 1', 'A.4_DikeIncrease 2', 'A.5_DikeIncrease 0', 'A.5_DikeIncrease 1', 'A.5_DikeIncrease 2']]\n",
    "policies_list = [Policy(str(index), **row.to_dict()) for index, row in policies.iterrows()]\n",
    "policies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add found policies to policy list\n",
    "policies = robust_results[['0_RfR 0', '0_RfR 1', '0_RfR 2', '1_RfR 0', '1_RfR 1', '1_RfR 2', '2_RfR 0', '2_RfR 1', '2_RfR 2', '3_RfR 0', '3_RfR 1', '3_RfR 2', '4_RfR 0', '4_RfR 1', '4_RfR 2', 'EWS_DaysToThreat', 'A.1_DikeIncrease 0', 'A.1_DikeIncrease 1', 'A.1_DikeIncrease 2', 'A.2_DikeIncrease 0', 'A.2_DikeIncrease 1', 'A.2_DikeIncrease 2', 'A.3_DikeIncrease 0', 'A.3_DikeIncrease 1', 'A.3_DikeIncrease 2', 'A.4_DikeIncrease 0', 'A.4_DikeIncrease 1', 'A.4_DikeIncrease 2', 'A.5_DikeIncrease 0', 'A.5_DikeIncrease 1', 'A.5_DikeIncrease 2']]\n",
    "policies1 = [Policy(str(index), **row.to_dict()) for index, row in policies.iterrows()]\n",
    "policies_list.append(policies1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-evaluate\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "   robust_1 = evaluator.perform_experiments(1000,\n",
    "                                         policies = policies_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(robust_1, 'ANALYSIS_results/03_robust_results.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f0ac929bf69e767d97169d4c3c2e590e3a5aa1e8190d34be53496fcb6d6f9aa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
