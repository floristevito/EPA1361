{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from ema_workbench.analysis import plotting, plotting_util, pairs_plotting, prim\n",
    "from ema_workbench import (RealParameter, ScalarOutcome, Constant,\n",
    "                           Model, MultiprocessingEvaluator, SequentialEvaluator, ema_logging,\n",
    "                           perform_experiments, Policy, Scenario)\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume,\n",
    "                                                     EpsilonProgress)\n",
    "from ema_workbench import Constraint\n",
    "from ema_workbench.util.utilities import (save_results, load_results)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define problem formulation\n",
    "model, functions = get_model_for_problem_formulation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up robust functions\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def robustness(direction, threshold, data):\n",
    "    if direction == 'SMALLER':\n",
    "        return np.sum(data<=threshold)/data.shape[0]\n",
    "    else:\n",
    "        return np.sum(data>=threshold)/data.shape[0]\n",
    "\n",
    "Expected_Annual_Damage = functools.partial(robustness, 'SMALLER', 1*10**6)\n",
    "Dike_Investment_Costs = functools.partial(robustness, 'SMALLER', 10*10**8)\t\n",
    "RfR_Investment_Costs = functools.partial(robustness, 'SMALLER', 1)\t\n",
    "Evacuation_Costs = functools.partial(robustness, 'SMALLER', 50000)\t\n",
    "Expected_Number_of_Deaths = functools.partial(robustness, 'SMALLER', 1)\n",
    "Minimum_water_level_full_network = functools.partial(robustness, 'LARGER', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the robustness functions\n",
    "robust = [ScalarOutcome('Expected_Damage', kind=ScalarOutcome.MAXIMIZE, variable_name='Expected Annual Damage',\n",
    "                        function=Expected_Annual_Damage),\n",
    "          ScalarOutcome('Dike_Costs', kind=ScalarOutcome.MAXIMIZE,variable_name='Dike Investment Costs',\n",
    "                        function=Dike_Investment_Costs),\n",
    "          ScalarOutcome('RfR_Costs', kind=ScalarOutcome.MAXIMIZE, variable_name='RfR Investment Costs', \n",
    "                        function=RfR_Investment_Costs),\n",
    "          ScalarOutcome('Evacuation_Costs', kind=ScalarOutcome.MAXIMIZE, variable_name='Evacuation Costs',\n",
    "                        function=Evacuation_Costs),\n",
    "          ScalarOutcome('Number_of_Deaths', kind=ScalarOutcome.MAXIMIZE, variable_name='Expected Number of Deaths',\n",
    "                        function=Expected_Number_of_Deaths),\n",
    "          ScalarOutcome('wl', kind=ScalarOutcome.MAXIMIZE, variable_name='Minimum water level full network',\n",
    "                        function=Minimum_water_level_full_network)   \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up convergence metrics\n",
    "convergence_metrics [HyperVolume(minimum=[0,0,0,0], maximum=[1, 1, 1, 1]), EpsilonProgress()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check epsilon and convergence\n",
    "def plot_epsilon_and_convergence(convergencedata):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "    ax1.plot(convergencedata.nfe, convergencedata.epsilon_progress)\n",
    "    ax1.set_ylabel('$\\epsilon$-progress')\n",
    "    ax2.plot(convergencedata.nfe, convergencedata.hypervolume)\n",
    "    ax2.set_ylabel('hypervolume')\n",
    "\n",
    "    ax1.set_xlabel('number of function evaluations')\n",
    "    ax2.set_xlabel('number of function evaluations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scenarios from PRIM analysis\n",
    "import pickle\n",
    "\n",
    "with open('ANALYSIS_results/02_PRIM_scenarios.txt', 'rb') as file:\n",
    "    scenarios = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform MORO\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    robust_results, convergence = evaluator.robust_optimize(robust, \n",
    "                                                    scenarios=scenarios,\n",
    "                                                    nfe = 10000,\n",
    "                                                    epsilons=[0.05, ] * len(robust)\n",
    "                                                    convergence=convergence_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect convergence\n",
    "plot_epsilon_and_convergence(convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust policies\n",
    "robust_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view plot\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "outcomes = robust_results.loc[:,['Fmax_P', 'Futility', 'Fintertia', 'Freliability']]\n",
    "limits = parcoords.get_limits(outcomes)\n",
    "axes = parcoords.ParallelAxes(limits)\n",
    "axes.plot(outcomes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "result.to_csv('ANALYSIS_results/03_MORO_results.csv')\n",
    "convergence.to_csv('ANALYSIS_results/03_MORO_convergence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the policies\n",
    "policies = robust_results[['0_RfR 0', '0_RfR 1', '0_RfR 2', '1_RfR 0', '1_RfR 1', '1_RfR 2', '2_RfR 0', '2_RfR 1', '2_RfR 2', '3_RfR 0', '3_RfR 1', '3_RfR 2', '4_RfR 0', '4_RfR 1', '4_RfR 2', 'EWS_DaysToThreat', 'A.1_DikeIncrease 0', 'A.1_DikeIncrease 1', 'A.1_DikeIncrease 2', 'A.2_DikeIncrease 0', 'A.2_DikeIncrease 1', 'A.2_DikeIncrease 2', 'A.3_DikeIncrease 0', 'A.3_DikeIncrease 1', 'A.3_DikeIncrease 2', 'A.4_DikeIncrease 0', 'A.4_DikeIncrease 1', 'A.4_DikeIncrease 2', 'A.5_DikeIncrease 0', 'A.5_DikeIncrease 1', 'A.5_DikeIncrease 2']]\n",
    "policies_list = [Policy(str(index), **row.to_dict()) for index, row in policies.iterrows()]\n",
    "policies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-evaluate\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    experiment_robust_2, result_robust_2 = evaluator.perform_experiments(1000,\n",
    "                                         policies = policies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get plot\n",
    "def prepair_data(experiment, results):\n",
    "    df = pd.DataFrame(results)\n",
    "    data = pd.concat([experiment, df], 1)\n",
    "    results_p = pd.DataFrame()\n",
    "    results_p['maxp'] = data.groupby('policy').apply(lambda x: maxp(x.max_P))\n",
    "    results_p['utility'] = data.groupby('policy').apply(lambda x: utility(x.utility))\n",
    "    results_p['intertia'] = data.groupby('policy').apply(lambda x: inertia(x.intertia))\n",
    "    results_p['reliability'] = data.groupby('policy').apply(lambda x: reliability(x.reliability))\n",
    "    \n",
    "    return results_p\n",
    "    \n",
    "da = prepair_data(experiment_robust_2, result_robust_2)\n",
    "limits = parcoords.get_limits(da)\n",
    "axes = parcoords.ParallelAxes(limits)\n",
    "axes.plot(da)\n",
    "plt.show()"
   ]
  }
 ]
}